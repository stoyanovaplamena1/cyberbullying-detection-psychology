{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b985e7-e09f-4d13-a3c9-08337ce9c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, math, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from scipy.sparse import hstack, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4282859-048a-40e8-b1e0-53d9c2d7a44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: C:\\Data Science\\Cyberbullying detection\\cyberbullying-detection-psychology\\artifacts | Timestamp: 20250905_214142\n"
     ]
    }
   ],
   "source": [
    "PROJECT_DIR = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_DIR / \"data\"\n",
    "ARTIFACTS_DIR = PROJECT_DIR / \"artifacts\"\n",
    "\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TS = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(\"Artifacts:\", ARTIFACTS_DIR, \"| Timestamp:\", TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e5257a-8508-42d4-926d-eadb7288c31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>is_bullying</th>\n",
       "      <th>word_len</th>\n",
       "      <th>only_mentions</th>\n",
       "      <th>tweet_text_clean</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>in other words katandandre your food was crapi...</td>\n",
       "      <td>word katandandre food crapilicious mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>why is aussietv so white mkr theblock imaceleb...</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>user a classy whore or more red velvet cupcakes</td>\n",
       "      <td>user classy whore red velvet cupcake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>user meh p thanks for the heads up but not too...</td>\n",
       "      <td>user meh p thanks head not concern another ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>user this is an isis account pretending to be ...</td>\n",
       "      <td>user isi account pretend kurdish account like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Raja5aab @Quickieleaks Yes, the test of god i...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>user user yes the test of god is that good or ...</td>\n",
       "      <td>user user yes test god good bad indifferent we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Itu sekolah ya bukan tempat bully! Ga jauh kay...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>itu sekolah ya bukan tempat bully ga jauh kaya...</td>\n",
       "      <td>itu sekolah ya bukan tempat bully ga jauh kaya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Karma. I hope it bites Kat on the butt. She is...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>karma i hope it bites kat on the butt she is j...</td>\n",
       "      <td>karma hope bite kat butt nasty mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@stockputout everything but mostly my priest</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>user everything but mostly my priest</td>\n",
       "      <td>user everything mostly priest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rebecca Black Drops Out of School Due to Bully...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>rebecca black drops out of school due to bullying</td>\n",
       "      <td>rebecca black drops school due bullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  \\\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "5  @Raja5aab @Quickieleaks Yes, the test of god i...  not_cyberbullying   \n",
       "6  Itu sekolah ya bukan tempat bully! Ga jauh kay...  not_cyberbullying   \n",
       "7  Karma. I hope it bites Kat on the butt. She is...  not_cyberbullying   \n",
       "8       @stockputout everything but mostly my priest  not_cyberbullying   \n",
       "9  Rebecca Black Drops Out of School Due to Bully...  not_cyberbullying   \n",
       "\n",
       "   is_bullying  word_len  only_mentions  \\\n",
       "0            0         9          False   \n",
       "1            0        14          False   \n",
       "2            0         9          False   \n",
       "3            0        18          False   \n",
       "4            0        18          False   \n",
       "5            0        23          False   \n",
       "6            0        10          False   \n",
       "7            0        14          False   \n",
       "8            0         6          False   \n",
       "9            0         9          False   \n",
       "\n",
       "                                    tweet_text_clean  \\\n",
       "0  in other words katandandre your food was crapi...   \n",
       "1  why is aussietv so white mkr theblock imaceleb...   \n",
       "2    user a classy whore or more red velvet cupcakes   \n",
       "3  user meh p thanks for the heads up but not too...   \n",
       "4  user this is an isis account pretending to be ...   \n",
       "5  user user yes the test of god is that good or ...   \n",
       "6  itu sekolah ya bukan tempat bully ga jauh kaya...   \n",
       "7  karma i hope it bites kat on the butt she is j...   \n",
       "8               user everything but mostly my priest   \n",
       "9  rebecca black drops out of school due to bullying   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0             word katandandre food crapilicious mkr  \n",
       "1  aussietv white mkr theblock imacelebrityau tod...  \n",
       "2               user classy whore red velvet cupcake  \n",
       "3  user meh p thanks head not concern another ang...  \n",
       "4  user isi account pretend kurdish account like ...  \n",
       "5  user user yes test god good bad indifferent we...  \n",
       "6  itu sekolah ya bukan tempat bully ga jauh kaya...  \n",
       "7                 karma hope bite kat butt nasty mkr  \n",
       "8                      user everything mostly priest  \n",
       "9            rebecca black drops school due bullying  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyberbullying_df = pd.read_parquet(DATA_DIR / \"cleaned_cyberbullying.parquet\")\n",
    "cyberbullying_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4d3ede-4607-4320-9599-41ae019a5716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cyberbullying — class counts:\n",
      "cyberbullying_type\n",
      "religion               7998\n",
      "age                    7992\n",
      "gender                 7960\n",
      "ethnicity              7960\n",
      "not_cyberbullying      7927\n",
      "other_cyberbullying    7753\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cyberbullying — is_bullying (0=not, 1=bullying):\n",
      "is_bullying\n",
      "1    39663\n",
      "0     7927\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Cyberbullying — class counts:\")\n",
    "print(cyberbullying_df[\"cyberbullying_type\"].value_counts())\n",
    "print(\"\\nCyberbullying — is_bullying (0=not, 1=bullying):\")\n",
    "print(cyberbullying_df[\"is_bullying\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca301450-3ed8-4cb1-9ea3-d6c590e79265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label_count</th>\n",
       "      <th>any_toxic</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>simple_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>d'aww matches background colour seemingly stuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "      <td>hey man really not trying edit war guy constan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\" more i can't make any real suggestions on im...</td>\n",
       "      <td>can't make real suggestions improvement wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "      <td>sir hero chance remember page that's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\" congratulations from me as well, use the too...</td>\n",
       "      <td>congratulations well use tools well talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>sorry word 'nonsense' offensive anyway not int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  label_count  \\\n",
       "0             0        0       0       0              0            0   \n",
       "1             0        0       0       0              0            0   \n",
       "2             0        0       0       0              0            0   \n",
       "3             0        0       0       0              0            0   \n",
       "4             0        0       0       0              0            0   \n",
       "5             0        0       0       0              0            0   \n",
       "6             1        1       0       1              0            4   \n",
       "7             0        0       0       0              0            0   \n",
       "8             0        0       0       0              0            0   \n",
       "9             0        0       0       0              0            0   \n",
       "\n",
       "   any_toxic                                         clean_text  \\\n",
       "0          0  explanation why the edits made under my userna...   \n",
       "1          0  d'aww! he matches this background colour i'm s...   \n",
       "2          0  hey man, i'm really not trying to edit war. it...   \n",
       "3          0  \" more i can't make any real suggestions on im...   \n",
       "4          0  you, sir, are my hero. any chance you remember...   \n",
       "5          0  \" congratulations from me as well, use the too...   \n",
       "6          1       cocksucker before you piss around on my work   \n",
       "7          0  your vandalism to the matt shirvington article...   \n",
       "8          0  sorry if the word 'nonsense' was offensive to ...   \n",
       "9          0  alignment on this subject and which are contra...   \n",
       "\n",
       "                                       simple_tokens  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  d'aww matches background colour seemingly stuc...  \n",
       "2  hey man really not trying edit war guy constan...  \n",
       "3  can't make real suggestions improvement wonder...  \n",
       "4               sir hero chance remember page that's  \n",
       "5           congratulations well use tools well talk  \n",
       "6                        cocksucker piss around work  \n",
       "7  vandalism matt shirvington article reverted pl...  \n",
       "8  sorry word 'nonsense' offensive anyway not int...  \n",
       "9               alignment subject contrary dulithgow  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = pd.read_parquet(DATA_DIR / \"cleaned_jigsaw.parquet\")\n",
    "toxic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89ab74f-0b43-4dc5-acf0-65e03276617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Toxic — labels per comment (label_count):\n",
      "label_count\n",
      "0    143346\n",
      "1      6360\n",
      "2      3480\n",
      "3      4209\n",
      "4      1760\n",
      "5       385\n",
      "6        31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Toxic — any_toxic (0=clean, 1=toxic-any):\n",
      "any_toxic\n",
      "0    143346\n",
      "1     16225\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nToxic — labels per comment (label_count):\")\n",
    "print(toxic_df[\"label_count\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nToxic — any_toxic (0=clean, 1=toxic-any):\")\n",
    "print(toxic_df[\"any_toxic\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491419a-2b00-41e8-baff-b5efd7bdf8c6",
   "metadata": {},
   "source": [
    "#### Make train / dev / test splits (70/10/20)\n",
    "\n",
    "I created stable 70/10/20 splits for both datasets.\n",
    "For the cyberbullying data, I stratified by cyberbullying_type so train/dev/test keep the same class proportions.\n",
    "For the Wikipedia (Jigsaw) data, I stratified by a coarse label_count bin (0, 1, ≥2) so the balance of clean vs. labeled comments is consistent across splits.\n",
    "I saved the row indices for each split to JSON to make the workflow reproducible and to prevent data leakage—train is for learning, dev for tuning, and test stays untouched for final evaluation.\n",
    "I set a fixed random seed so the splits are stable across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855a15db-6817-4bdb-90cd-009c2a7be3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cyberbullying splits to artifacts/cb_splits.json\n"
     ]
    }
   ],
   "source": [
    "# Stratify tweets by the multiclass label: 'cyberbullying_type'\n",
    "\n",
    "cb_all_idx = np.arange(len(cyberbullying_df))\n",
    "cb_labels  = cyberbullying_df[\"cyberbullying_type\"]\n",
    "\n",
    "# First split: 80% (train+dev) and 20% (test)\n",
    "\n",
    "cb_trdev_idx, cb_test_idx = train_test_split(\n",
    "    cb_all_idx,\n",
    "    test_size=0.20,\n",
    "    stratify=cb_labels,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Second split: from train+dev 12.5% for dev (10% of full data)\n",
    "\n",
    "cb_trdev_labels = cb_labels.iloc[cb_trdev_idx]\n",
    "cb_train_idx, cb_dev_idx = train_test_split(\n",
    "    cb_trdev_idx,\n",
    "    test_size=0.125,\n",
    "    stratify=cb_trdev_labels,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Save\n",
    "cb_splits = {\n",
    "    \"train\": cb_train_idx.tolist(),\n",
    "    \"dev\":   cb_dev_idx.tolist(),\n",
    "    \"test\":  cb_test_idx.tolist(),\n",
    "}\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"cb_splits.json\"), \"w\") as f:\n",
    "    json.dump(cb_splits, f, indent=2)\n",
    "print(\"Saved cyberbullying splits to artifacts/cb_splits.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81bc41e7-9419-4b8f-9a8b-81b058d1bf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Cyberbullying] sizes: train = 33313 dev = 4759 test = 9518\n",
      "[Cyberbullying] label proportions by split (should look similar):\n",
      "  train → {'religion': 0.168, 'age': 0.168, 'gender': 0.167, 'ethnicity': 0.167, 'not_cyberbullying': 0.167, 'other_cyberbullying': 0.163}\n",
      "  dev → {'religion': 0.168, 'age': 0.168, 'ethnicity': 0.167, 'gender': 0.167, 'not_cyberbullying': 0.167, 'other_cyberbullying': 0.163}\n",
      "  test → {'religion': 0.168, 'age': 0.168, 'ethnicity': 0.167, 'gender': 0.167, 'not_cyberbullying': 0.167, 'other_cyberbullying': 0.163}\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity prints (sizes and label proportions)\n",
    "print(\"\\n[Cyberbullying] sizes:\",\n",
    "      \"train =\", len(cb_train_idx),\n",
    "      \"dev =\", len(cb_dev_idx),\n",
    "      \"test =\", len(cb_test_idx))\n",
    "\n",
    "print(\"[Cyberbullying] label proportions by split (should look similar):\")\n",
    "for name, idx in [(\"train\", cb_train_idx), (\"dev\", cb_dev_idx), (\"test\", cb_test_idx)]:\n",
    "    props = cyberbullying_df.iloc[idx][\"cyberbullying_type\"].value_counts(normalize=True)\n",
    "    print(f\"  {name} →\", props.round(3).to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cc6b044-37a3-4e4d-8cb2-4ba6dec01008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved toxic splits to artifacts/tx_splits.json\n"
     ]
    }
   ],
   "source": [
    "# Stratify jigsaw data by a coarse version of label_count: 0, 1, 2+\n",
    "\n",
    "tx_all_idx = np.arange(len(toxic_df))\n",
    "tx_bins = toxic_df[\"label_count\"].clip(0, 2)  # 0 stays 0, 1 stays 1, 2/3/4/5/6 become 2\n",
    "\n",
    "# First split: 80% (train+dev) and 20% (test)\n",
    "tx_trdev_idx, tx_test_idx = train_test_split(\n",
    "    tx_all_idx,\n",
    "    test_size=0.20,\n",
    "    stratify=tx_bins,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Second split: from train+dev 12.5% for dev (10% of full data)\n",
    "tx_trdev_bins = tx_bins.iloc[tx_trdev_idx]\n",
    "tx_train_idx, tx_dev_idx = train_test_split(\n",
    "    tx_trdev_idx,\n",
    "    test_size=0.125,\n",
    "    stratify=tx_trdev_bins,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Save\n",
    "tx_splits = {\n",
    "    \"train\": tx_train_idx.tolist(),\n",
    "    \"dev\":   tx_dev_idx.tolist(),\n",
    "    \"test\":  tx_test_idx.tolist(),\n",
    "}\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"tx_splits.json\"), \"w\") as f:\n",
    "    json.dump(tx_splits, f, indent=2)\n",
    "print(\"Saved toxic splits to artifacts/tx_splits.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e094a07b-c044-4693-8bbe-78793406cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Toxic] sizes: train = 111699 dev = 15957 test = 31915\n",
      "[Toxic] label_count bins {0,1,2+} by split (should look similar):\n",
      "  train → {0: 0.898, 1: 0.04, 2: 0.062}\n",
      "  dev → {0: 0.898, 1: 0.04, 2: 0.062}\n",
      "  test → {0: 0.898, 1: 0.04, 2: 0.062}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check (sizes and label_count proportions)\n",
    "print(\"\\n[Toxic] sizes:\",\n",
    "      \"train =\", len(tx_train_idx),\n",
    "      \"dev =\", len(tx_dev_idx),\n",
    "      \"test =\", len(tx_test_idx))\n",
    "\n",
    "print(\"[Toxic] label_count bins {0,1,2+} by split (should look similar):\")\n",
    "for name, idx in [(\"train\", tx_train_idx), (\"dev\", tx_dev_idx), (\"test\", tx_test_idx)]:\n",
    "    props = toxic_df.iloc[idx][\"label_count\"].clip(0,2).value_counts(normalize=True).sort_index()\n",
    "    # pretty print as dict: {0: 0.xxx, 1: 0.xxx, 2: 0.xxx}\n",
    "    print(f\"  {name} →\", {int(k): round(v, 3) for k, v in props.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d185e-a0d2-4369-8369-b107323b7611",
   "metadata": {},
   "source": [
    "#### Word TF–IDF\n",
    "\n",
    "I use TF–IDF because it gives me a solid, interpretable baseline that connects directly to my research questions. I need a feature space that (a) works the same way on both datasets, (b) highlights informative language (insults, slurs, threats, requests), and (c) lets me see what the model is using. TF–IDF does that: term frequency captures how much a word or phrase appears in a comment, and inverse document frequency down-weights routine words. That means coordination terms on Wikipedia (“article”, “page”, “thanks”) get naturally de-emphasized, while hostile or targeted language pops out.\n",
    "\n",
    "I loaded the same train/dev/test splits I saved earlier. I then took the text I want to model: lemmatized_text for the cyberbullying tweets and simple_tokens for the Jigsaw comments. I turned those texts into numbers with a word TF–IDF vectorizer. I count how often each word (and each two-word phrase) appears in a document, then down-weight words that are very common across many documents. That gives me features that highlight informative words and short phrases.\n",
    "\n",
    "I made one vectorizer per dataset (Twitter and Wikipedia), because the vocabularies differ. For each dataset, I fit the vectorizer on the training split only (to avoid peeking at dev/test). I used unigrams and bigrams (ngram_range=(1,2)), ignored ultra-rare terms (min_df=3), and capped the vocabulary size (max_features=50_000) so the matrices don’t blow up. After fitting on train, I transformed the dev and test splits with the same fitted vectorizer, so all three splits live in the exact same feature space.\n",
    "\n",
    "I saved both fitted vectorizers to the artifacts/ folder so later notebooks can reload them and get identical features. Finally, I printed the matrix shapes to sanity-check things: the number of rows matches the number of examples in each split, and the number of columns equals the learned vocabulary size for that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3d17e83-3c1d-405b-b51d-436c631bc501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved vectorizers: tfidf_word_cyberbullying.joblib, tfidf_word_toxic.joblib\n",
      "[Cyberbullying] word TF–IDF shapes:\n",
      "  train: (33313, 27410) dev: (4759, 27410) test: (9518, 27410)\n",
      "[Toxic] word TF–IDF shapes:\n",
      "  train: (111699, 50000) dev: (15957, 50000) test: (31915, 50000)\n"
     ]
    }
   ],
   "source": [
    "# Load the splits \n",
    "with open(os.path.join(ARTIFACTS_DIR, \"cb_splits.json\")) as f:\n",
    "    cb_splits = json.load(f)\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"tx_splits.json\")) as f:\n",
    "    tx_splits = json.load(f)\n",
    "\n",
    "# Slice the dataframes into train/dev/test\n",
    "cb_train = cyberbullying_df.iloc[cb_splits[\"train\"]]\n",
    "cb_dev   = cyberbullying_df.iloc[cb_splits[\"dev\"]]\n",
    "cb_test  = cyberbullying_df.iloc[cb_splits[\"test\"]]\n",
    "\n",
    "tx_train = toxic_df.iloc[tx_splits[\"train\"]]\n",
    "tx_dev   = toxic_df.iloc[tx_splits[\"dev\"]]\n",
    "tx_test  = toxic_df.iloc[tx_splits[\"test\"]]\n",
    "\n",
    "# Pull the text columns to vectorize \n",
    "cb_train_text = cb_train[\"lemmatized_text\"]\n",
    "cb_dev_text   = cb_dev[\"lemmatized_text\"]\n",
    "cb_test_text  = cb_test[\"lemmatized_text\"]\n",
    "\n",
    "tx_train_text = tx_train[\"simple_tokens\"]\n",
    "tx_dev_text   = tx_dev[\"simple_tokens\"]\n",
    "tx_test_text  = tx_test[\"simple_tokens\"]\n",
    "\n",
    "# Make the TF–IDF vectorizers \n",
    "cb_word_vec = TfidfVectorizer(ngram_range=(1,2), min_df=3, max_features=50_000)\n",
    "tx_word_vec = TfidfVectorizer(ngram_range=(1,2), min_df=3, max_features=50_000)\n",
    "\n",
    "# Fit on TRAIN only\n",
    "Xw_cb_train = cb_word_vec.fit_transform(cb_train_text)\n",
    "Xw_tx_train = tx_word_vec.fit_transform(tx_train_text)\n",
    "\n",
    "# Ttansform dev and test with the fitted vectorizers\n",
    "Xw_cb_dev  = cb_word_vec.transform(cb_dev_text)\n",
    "Xw_cb_test = cb_word_vec.transform(cb_test_text)\n",
    "\n",
    "Xw_tx_dev  = tx_word_vec.transform(tx_dev_text)\n",
    "Xw_tx_test = tx_word_vec.transform(tx_test_text)\n",
    "\n",
    "# Save the fitted vectorizers so future notebooks can load them\n",
    "joblib.dump(cb_word_vec, os.path.join(ARTIFACTS_DIR, \"tfidf_word_cyberbullying.joblib\"))\n",
    "joblib.dump(tx_word_vec, os.path.join(ARTIFACTS_DIR, \"tfidf_word_toxic.joblib\"))\n",
    "print(\"Saved vectorizers: tfidf_word_cyberbullying.joblib, tfidf_word_toxic.joblib\")\n",
    "\n",
    "# Quick sanity checks: show shapes (rows = examples, cols = vocab size)\n",
    "print(\"[Cyberbullying] word TF–IDF shapes:\")\n",
    "print(\"  train:\", Xw_cb_train.shape, \"dev:\", Xw_cb_dev.shape, \"test:\", Xw_cb_test.shape)\n",
    "\n",
    "print(\"[Toxic] word TF–IDF shapes:\")\n",
    "print(\"  train:\", Xw_tx_train.shape, \"dev:\", Xw_tx_dev.shape, \"test:\", Xw_tx_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf6a1c-c40f-4e1d-b6d9-df6f809a79b6",
   "metadata": {},
   "source": [
    "#### Why word + char TF–IDF\n",
    "\n",
    "I build word TF–IDF to capture clear semantics (single words and short phrases) and character TF–IDF to catch obfuscation and style (misspellings, elongations, punctuation runs). Together, they cover both what is said and how it is written. This matters for my hypotheses: H1 (style differences), H2 (domain norms), and H4 (severity × target). For example, word TF–IDF surfaces slurs and violence verbs (severity), while char TF–IDF still fires when users mask them (“f*ck”, “idi0t”).\n",
    "\n",
    "TF–IDF also supports fair, reproducible evaluation. I fit the vectorizers on train only, so I don’t leak information into dev/test. The resulting sparse matrices let me train simple linear models and inspect coefficients to check for identity-term bias (H3): I can see if the model leans too hard on a group word and then fix that in features or thresholds. Finally, TF–IDF gives me a shared backbone for both tasks—multiclass Twitter and multilabel Wikipedia—so I can compare precision/recall behavior (H1), examine cross-domain drift (H2), and run clean-vs-toxic analyses.\n",
    "\n",
    "#### Character TF–IDF\n",
    "I added character n-gram TF–IDF because people often hide or vary abusive words with spelling tricks and emphasis. Examples: f*ck, fuuuck, idi0t, bi—tch, or long runs of !!!. Word features miss these if the exact token is new, but character 3–5-grams still fire on the shared subpieces (fuc, uck, idi, i0t). Char n-grams also catch style signals that live in the stream itself (elongations, punctuation, casing) rather than in dictionary words. This makes the representation more robust and complements word TF–IDF (which gives clean semantics).\n",
    "\n",
    "For preprocessing I chose slightly different inputs:\n",
    "\n",
    "- Cyberbullying: tweet_text_clean, which keeps the natural character stream I care about (repeats, punctuation) but removes junk that would dominate the signal (URLs) and normalizes mentions to a single @user.\n",
    "\n",
    "- Jigsaw: raw comment_text. On Wikipedia I didn’t lemmatize; the raw comments already contain the punctuation and elongations that char n-grams need, and URLs are less dominant there.\n",
    "\n",
    "Settings:\n",
    "\n",
    "- ngram_range=(3,5) to balance detail and noise. Unigrams/bigrams at the character level are too generic (they light up everywhere: th, he, in). Very long n-grams explode the feature space and act like brittle exact matches.\n",
    "\n",
    "- min_df=5 to ignore character sequences that occur in only a handful of comments; that removes one-off typos and reduces overfitting.\n",
    "\n",
    "- max_features=30_000 to keep memory and training time reasonable; word TF–IDF already carries the heavy semantic load, so the char block only needs to cover the most common subword patterns.\n",
    "\n",
    "I fit the char vectorizers on the train split only to avoid leaking information from dev/test into the vocabulary, then I transformed dev and test with the same fitted vectorizer so all splits live in the exact same feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867fc55-633a-456b-b3de-a53e98c6a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_CHAR_COL = \"tweet_text_clean\"\n",
    "TX_CHAR_COL = \"comment_text\"\n",
    "\n",
    "cb_train_char = cb_train[CB_CHAR_COL]\n",
    "cb_dev_char   = cb_dev[CB_CHAR_COL]\n",
    "cb_test_char  = cb_test[CB_CHAR_COL]\n",
    "\n",
    "tx_train_char = tx_train[TX_CHAR_COL]\n",
    "tx_dev_char   = tx_dev[TX_CHAR_COL]\n",
    "tx_test_char  = tx_test[TX_CHAR_COL]\n",
    "\n",
    "\n",
    "# Build the character TF–IDF vectorizers\n",
    "cb_char_vec = TfidfVectorizer(analyzer=\"char\", ngram_range=(3,5), min_df=5, max_features=30_000)\n",
    "tx_char_vec = TfidfVectorizer(analyzer=\"char\", ngram_range=(3,5), min_df=5, max_features=30_000)\n",
    "\n",
    "# Fit on train only\n",
    "Xc_cb_train = cb_char_vec.fit_transform(cb_train_char)\n",
    "Xc_tx_train = tx_char_vec.fit_transform(tx_train_char)\n",
    "\n",
    "# Transform dev and test with the same fitted vectorizers\n",
    "Xc_cb_dev  = cb_char_vec.transform(cb_dev_char)\n",
    "Xc_cb_test = cb_char_vec.transform(cb_test_char)\n",
    "\n",
    "Xc_tx_dev  = tx_char_vec.transform(tx_dev_char)\n",
    "Xc_tx_test = tx_char_vec.transform(tx_test_char)\n",
    "\n",
    "# Save the fitted vectorizers\n",
    "joblib.dump(cb_char_vec, os.path.join(ARTIFACTS_DIR, \"tfidf_char_cyberbullying.joblib\"))\n",
    "joblib.dump(tx_char_vec, os.path.join(ARTIFACTS_DIR, \"tfidf_char_toxic.joblib\"))\n",
    "print(\"Saved vectorizers: tfidf_char_cyberbullying.joblib, tfidf_char_toxic.joblib\")\n",
    "\n",
    "# Sanity-check shapes\n",
    "print(\"[Cyberbullying] char TF–IDF shapes:\")\n",
    "print(\"  train:\", Xc_cb_train.shape, \"dev:\", Xc_cb_dev.shape, \"test:\", Xc_cb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e4d327-e2e3-4a18-92aa-e14472f915b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFANITY  = {\"fuck\",\"fucking\",\"shit\",\"bitch\",\"cunt\",\"ass\",\"dick\",\"suck\",\"sucks\",\"moron\",\"stupid\"}\n",
    "VIOLENCE   = {\"kill\",\"die\",\"murder\",\"hurt\",\"destroy\",\"stab\",\"shoot\"}\n",
    "PRON_2ND   = {\"you\",\"your\",\"u\",\"ur\",\"you're\",\"youre\"}\n",
    "INTENS     = {\"very\",\"really\",\"so\",\"extremely\",\"totally\",\"absolutely\",\"super\"}\n",
    "POLITE     = {\"please\",\"thank\",\"thanks\",\"appreciate\"}\n",
    "NEGATE     = {\n",
    "    \"not\",\"no\",\"never\",\n",
    "    \"don't\",\"dont\",\"can't\",\"cant\",\"won't\",\"wont\",\"isn't\",\"isnt\",\"didn't\",\"didnt\",\n",
    "    \"doesn't\",\"doesnt\",\"shouldn't\",\"shouldnt\",\"couldn't\",\"couldnt\",\"wouldn't\",\"wouldnt\",\n",
    "    \"ain't\",\"aint\",\"n't\"\n",
    "}\n",
    "IDENTITY   = {\"jew\",\"jewish\",\"muslim\",\"christian\",\"black\",\"white\",\"gay\",\"lesbian\",\"mexican\",\"mexicans\"}\n",
    "GENERALIZ  = {\"these\",\"those\",\"all\",\"every\",\"always\",\"everyone\",\"nobody\"}\n",
    "HEDGES_UNI = {\"maybe\",\"perhaps\",\"seems\",\"apparently\",\"probably\",\"possibly\",\"likely\"}\n",
    "HEDGE_PHRASES = {\"i think\",\"i guess\",\"sort of\",\"kind of\"}\n",
    "\n",
    "URL_RE     = re.compile(r\"(https?://\\S+|www\\.\\S+)\", re.IGNORECASE)\n",
    "MENTION_RE = re.compile(r\"@\\w+\")\n",
    "HASHTAG_RE = re.compile(r\"#(\\w+)\")\n",
    "\n",
    "def _tokens(series: pd.Series):\n",
    "    return series.fillna(\"\").astype(str).str.split()\n",
    "\n",
    "def _rate_per_k(tokens, lexicon, per=1000, min_tokens=20):\n",
    "    \"\"\"\n",
    "    Per-1k rate with length smoothing: treat very short messages as if they had\n",
    "    at least `min_tokens` tokens to avoid huge spikes like 333 when n=3.\n",
    "    \"\"\"\n",
    "    n = max(len(tokens), min_tokens)\n",
    "    return 0.0 if n == 0 else per * sum(1 for t in tokens if t in lexicon) / n\n",
    "\n",
    "def _has_any(tokens, lexicon):\n",
    "    return int(any(t in lexicon for t in tokens))\n",
    "\n",
    "def _has_any_bigram(tokens, phrases):\n",
    "    s = \" \".join(tokens)\n",
    "    return int(any(p in s for p in phrases))\n",
    "\n",
    "def _raw_counts(text):\n",
    "    s = \"\" if not isinstance(text, str) else text\n",
    "    had_url      = int(bool(URL_RE.search(s)))\n",
    "    had_mention  = int(bool(MENTION_RE.search(s)))\n",
    "    hashtag_count= len(HASHTAG_RE.findall(s))\n",
    "    bangs        = s.count(\"!\")\n",
    "    qmarks       = s.count(\"?\")\n",
    "    return had_url, had_mention, hashtag_count, bangs, qmarks\n",
    "\n",
    "def build_psych_features_smooth(\n",
    "    df: pd.DataFrame, tokens_col: str, raw_col: str, per: int = 1000, min_tokens: int = 20\n",
    ") -> pd.DataFrame:\n",
    "    toks_series = _tokens(df[tokens_col])\n",
    "\n",
    "    rows = []\n",
    "    for i, ts in enumerate(toks_series):\n",
    "        # per-1k (smoothed) lexicon rates\n",
    "        rate_profane   = _rate_per_k(ts, PROFANITY,  per=per, min_tokens=min_tokens)\n",
    "        rate_violence  = _rate_per_k(ts, VIOLENCE,   per=per, min_tokens=min_tokens)\n",
    "        rate_2nd       = _rate_per_k(ts, PRON_2ND,   per=per, min_tokens=min_tokens)\n",
    "        rate_intens    = _rate_per_k(ts, INTENS,     per=per, min_tokens=min_tokens)\n",
    "        rate_negate    = _rate_per_k(ts, NEGATE,     per=per, min_tokens=min_tokens)\n",
    "        rate_polite    = _rate_per_k(ts, POLITE,     per=per, min_tokens=min_tokens)\n",
    "        rate_identity  = _rate_per_k(ts, IDENTITY,   per=per, min_tokens=min_tokens)\n",
    "        rate_general   = _rate_per_k(ts, GENERALIZ,  per=per, min_tokens=min_tokens)\n",
    "        rate_hedge     = _rate_per_k(ts, HEDGES_UNI, per=per, min_tokens=min_tokens)\n",
    "\n",
    "        # flags + controls\n",
    "        has_profane    = _has_any(ts, PROFANITY)\n",
    "        has_identity   = _has_any(ts, IDENTITY)\n",
    "        has_hedge_bigram = _has_any_bigram(ts, HEDGE_PHRASES)\n",
    "\n",
    "        n_tokens    = len(ts)\n",
    "        n_smooth    = max(n_tokens, min_tokens)\n",
    "        avg_tok_len = float(np.mean([len(t) for t in ts])) if n_tokens > 0 else 0.0\n",
    "\n",
    "        raw = df.iloc[i][raw_col] if raw_col in df.columns else \"\"\n",
    "        had_url, had_mention, hashtag_count, bangs, qmarks = _raw_counts(raw)\n",
    "\n",
    "        # per-1k (smoothed) normalized raw signals\n",
    "        rate_bangs     = per * bangs / n_smooth\n",
    "        rate_qmarks    = per * qmarks / n_smooth\n",
    "        rate_hashtags  = per * hashtag_count / n_smooth\n",
    "\n",
    "        rows.append({\n",
    "            # rates (lexicons)\n",
    "            \"rate_profane\":  rate_profane,\n",
    "            \"rate_violence\": rate_violence,\n",
    "            \"rate_2nd\":      rate_2nd,\n",
    "            \"rate_intens\":   rate_intens,\n",
    "            \"rate_negate\":   rate_negate,\n",
    "            \"rate_polite\":   rate_polite,\n",
    "            \"rate_identity\": rate_identity,\n",
    "            \"rate_general\":  rate_general,\n",
    "            \"rate_hedge\":    rate_hedge,\n",
    "            # rates (normalized raw)\n",
    "            \"rate_bangs\":    rate_bangs,\n",
    "            \"rate_qmarks\":   rate_qmarks,\n",
    "            \"rate_hashtags\": rate_hashtags,\n",
    "            # flags + controls\n",
    "            \"has_profane\":   has_profane,\n",
    "            \"has_identity\":  has_identity,\n",
    "            \"has_hedge_bigram\": has_hedge_bigram,\n",
    "            \"n_tokens\":      n_tokens,\n",
    "            \"avg_tok_len\":   avg_tok_len,\n",
    "            \"had_url\":       had_url,\n",
    "            \"had_mention\":   had_mention,\n",
    "        })\n",
    "\n",
    "    cols = [\n",
    "        \"rate_profane\",\"rate_violence\",\"rate_2nd\",\"rate_intens\",\"rate_negate\",\"rate_polite\",\n",
    "        \"rate_identity\",\"rate_general\",\"rate_hedge\",\n",
    "        \"rate_bangs\",\"rate_qmarks\",\"rate_hashtags\",\n",
    "        \"has_profane\",\"has_identity\",\"has_hedge_bigram\",\n",
    "        \"n_tokens\",\"avg_tok_len\",\"had_url\",\"had_mention\"\n",
    "    ]\n",
    "    feats = pd.DataFrame(rows, index=df.index)[cols]\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95123b70-182e-49fb-9536-acde0422097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features for each split\n",
    "\n",
    "cb_psy_tr = build_psych_features_smooth(cb_train, tokens_col=\"lemmatized_text\", raw_col=\"tweet_text\")\n",
    "cb_psy_dv = build_psych_features_smooth(cb_dev,   tokens_col=\"lemmatized_text\", raw_col=\"tweet_text\")\n",
    "cb_psy_te = build_psych_features_smooth(cb_test,  tokens_col=\"lemmatized_text\", raw_col=\"tweet_text\")\n",
    "\n",
    "tx_psy_tr = build_psych_features_smooth(tx_train, tokens_col=\"simple_tokens\",   raw_col=\"comment_text\")\n",
    "tx_psy_dv = build_psych_features_smooth(tx_dev,   tokens_col=\"simple_tokens\",   raw_col=\"comment_text\")\n",
    "tx_psy_te = build_psych_features_smooth(tx_test,  tokens_col=\"simple_tokens\",   raw_col=\"comment_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d1186-c8b5-49d6-a20e-dec7ddecd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tx_psy_tr.filter(like=\"rate_\").mean().round(2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86edaa-f6a8-4d7b-9574-a5511cfedd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_cues_train_dev_test(tr_df, dv_df, te_df, name_prefix):\n",
    "    \"\"\"\n",
    "    Fit MaxAbsScaler on train cue features (DataFrame), transform dev/test,\n",
    "    convert to CSR sparse, and persist scaler + matrices.\n",
    "    \"\"\"\n",
    "    scaler = MaxAbsScaler()\n",
    "    tr_scaled = scaler.fit_transform(tr_df.values)\n",
    "    dv_scaled = scaler.transform(dv_df.values)\n",
    "    te_scaled = scaler.transform(te_df.values)\n",
    "\n",
    "    X_tr = csr_matrix(tr_scaled)\n",
    "    X_dv = csr_matrix(dv_scaled)\n",
    "    X_te = csr_matrix(te_scaled)\n",
    "\n",
    "    # Save scaler + split-aligned matrices\n",
    "    joblib.dump(scaler, os.path.join(ARTIFACTS_DIR, f\"{name_prefix}_scaler.joblib\"))\n",
    "    joblib.dump({\"train\": X_tr, \"dev\": X_dv, \"test\": X_te},\n",
    "                os.path.join(ARTIFACTS_DIR, f\"{name_prefix}_scaled.joblib\"))\n",
    "\n",
    "    # Quick sanity: show column count and a few norms (should be <= 1 after MaxAbs)\n",
    "    colmax_train = np.abs(tr_scaled).max(axis=0)\n",
    "    print(f\"[{name_prefix}] cols: {tr_df.shape[1]}, max abs per-col (train) ≤ 1: {np.all(colmax_train <= 1.000001)}\")\n",
    "    return X_tr, X_dv, X_te\n",
    "\n",
    "# Run for both corpora\n",
    "Xp_cb_tr, Xp_cb_dv, Xp_cb_te = scale_cues_train_dev_test(cb_psy_tr, cb_psy_dv, cb_psy_te, name_prefix=\"cb_cues\")\n",
    "Xp_tx_tr, Xp_tx_dv, Xp_tx_te = scale_cues_train_dev_test(tx_psy_tr, tx_psy_dv, tx_psy_te, name_prefix=\"tx_cues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d09272-a835-4510-ac00-8be0f985106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cb_train = hstack([Xw_cb_train, Xc_cb_train, Xp_cb_tr], format=\"csr\")\n",
    "X_cb_dev   = hstack([Xw_cb_dev,   Xc_cb_dev,   Xp_cb_dv], format=\"csr\")\n",
    "X_cb_test  = hstack([Xw_cb_test,  Xc_cb_test,  Xp_cb_te], format=\"csr\")\n",
    "\n",
    "joblib.dump({\"train\": X_cb_train, \"dev\": X_cb_dev, \"test\": X_cb_test},\n",
    "            os.path.join(ARTIFACTS_DIR, \"cb_word_char_cues.joblib\"), compress=3)\n",
    "print(\"[SAVED] artifacts/cb_word_char_cues.joblib\",\n",
    "      \"→\", X_cb_train.shape, X_cb_dev.shape, X_cb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b8b1f-5131-4af1-9c05-4749b986596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tx_train = hstack([Xw_tx_train, Xc_tx_train, Xp_tx_tr], format=\"csr\")\n",
    "X_tx_dev   = hstack([Xw_tx_dev,   Xc_tx_dev,   Xp_tx_dv], format=\"csr\")\n",
    "X_tx_test  = hstack([Xw_tx_test,  Xc_tx_test,  Xp_tx_te], format=\"csr\")\n",
    "\n",
    "joblib.dump({\"train\": X_tx_train, \"dev\": X_tx_dev, \"test\": X_tx_test},\n",
    "            os.path.join(ARTIFACTS_DIR, \"tx_word_char_cues.joblib\"), compress=3)\n",
    "print(\"[SAVED] artifacts/tx_word_char_cues.joblib\",\n",
    "      \"→\", X_tx_train.shape, X_tx_dev.shape, X_tx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbcbf31-7a04-4c11-8353-ae285bee80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cb_bin = {\n",
    "    \"train\": cb_train[\"is_bullying\"].astype(int).values,\n",
    "    \"dev\":   cb_dev[\"is_bullying\"].astype(int).values,\n",
    "    \"test\":  cb_test[\"is_bullying\"].astype(int).values,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd265b-7aa5-403f-b1c1-726fa8a1aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass codes (0..K-1) + mapping for reproducibility\n",
    "cats = cb_train[\"cyberbullying_type\"].astype(\"category\").cat.categories\n",
    "# Use a consistent global mapping across splits:\n",
    "all_cats = cb_train[\"cyberbullying_type\"].astype(\"category\").cat.categories\n",
    "code_map = {cat: i for i, cat in enumerate(all_cats)}\n",
    "\n",
    "\n",
    "def _codes(s): return np.array([code_map[v] for v in s])\n",
    "    \n",
    "y_cb_mc = {\n",
    "    \"train\": _codes(cb_train[\"cyberbullying_type\"]),\n",
    "    \"dev\":   _codes(cb_dev[\"cyberbullying_type\"]),\n",
    "    \"test\":  _codes(cb_test[\"cyberbullying_type\"]),\n",
    "}\n",
    "\n",
    "joblib.dump(\n",
    "    {\"binary\": y_cb_bin, \"multiclass\": y_cb_mc, \"mapping\": code_map},\n",
    "    os.path.join(ARTIFACTS_DIR, \"cb_labels.joblib\"),\n",
    ")\n",
    "print(\"[SAVED] artifacts/cb_labels.joblib\",\n",
    "      f\"→ binary sizes {[len(y) for y in y_cb_bin.values()]} ; multiclass sizes {[len(y) for y in y_cb_mc.values()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7da6d-78c2-4116-aaee-c3940bd8dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_LABELS = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "Y_tx_train = tx_train[TX_LABELS].astype(int).to_numpy()\n",
    "Y_tx_dev   = tx_dev[TX_LABELS].astype(int).to_numpy()\n",
    "Y_tx_test  = tx_test[TX_LABELS].astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ad7b6-3936-47c2-81de-c5f809f46be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save multi-label Y matrices\n",
    "Y_tx = {\"train\": Y_tx_train, \"dev\": Y_tx_dev, \"test\": Y_tx_test}\n",
    "joblib.dump(Y_tx, os.path.join(ARTIFACTS_DIR, \"tx_multilabel.joblib\"))\n",
    "print(\"[SAVED] artifacts/tx_multilabel.joblib\",\n",
    "      f\"→ shapes {[Y_tx[k].shape for k in ['train','dev','test']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772be6a-8878-4f48-9b6e-f4e8f47ee49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUE_NAMES_CB = cb_psy_tr.columns.tolist()\n",
    "CUE_NAMES_TX = tx_psy_tr.columns.tolist()\n",
    "\n",
    "joblib.dump(CUE_NAMES_CB, os.path.join(ARTIFACTS_DIR, \"cb_cue_columns.joblib\"))\n",
    "joblib.dump(CUE_NAMES_TX, os.path.join(ARTIFACTS_DIR, \"tx_cue_columns.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4642d-69d5-4e6a-a073-1af1f6f2a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_LABELS = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "joblib.dump(TX_LABELS, ARTIFACTS_DIR / \"tx_label_order.joblib\")\n",
    "print(\"Saved →\", ARTIFACTS_DIR / \"tx_label_order.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cbdetect)",
   "language": "python",
   "name": "cbdetect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
